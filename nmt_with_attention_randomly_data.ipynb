{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt_with_attention_randomly data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3612jvsc74a57bd0930e46df0d1b93ecf8fe51f04b6e478dce688000f1283825e61bc5e483dc45d1",
      "display_name": "Python 3.6.12 64-bit ('tensorflow': conda)"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-3B58nFmAuK"
      },
      "source": [
        "# 랜덤 o\n",
        "# [0:30000] randomly 3번\n",
        "# 총 3개 모델을 Ensemble\n",
        "# Soft Voting"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gw4c03iuGtO"
      },
      "source": [
        "# Training Data - training checkpoints\n",
        "# 1. path_to_file 바꿔주기\n",
        "# 2. 모델 Test 시에는 shuffle_file 생성 코드 주석처리!\n",
        "# 3. create_data, load_data 의 path_to_file 변경\n",
        "# 4. checkpoint_dir 도 변경"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcQ_b7BlfLKg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9b9289-b77b-4c1d-bfa8-f52b540d5c65"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C5I92usDlWa"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import random"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LGie5tSDrLl"
      },
      "source": [
        "# # 파일을 다운로드합니다.\n",
        "# path_to_zip = tf.keras.utils.get_file(\n",
        "#     'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "#     extract=True)\n",
        "\n",
        "# path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\"\n",
        "path_to_file = '/content/drive/MyDrive/Colab Notebooks/spa-eng/spa.txt'\n",
        "path_to_shuffle_file = '/content/drive/MyDrive/Colab Notebooks/spa-eng/shuffle_spa-eng.txt'\n",
        "path_to_shuffle_file2 = '/content/drive/MyDrive/Colab Notebooks/spa-eng/shuffle_spa-eng2.txt'\n",
        "# path_to_shuffle_file3 = '/content/drive/MyDrive/Colab Notebooks/spa-eng/shuffle_spa-eng3.txt'\n",
        "path_to_shuffle_file3 = '//Users/ahjeong_park/Study/Attention-Ensemble-Translation/spa-eng/shuffle_spa-eng3.txt'\n",
        "\n",
        "\n",
        "# print(path_to_file)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCTS3Es_EJl-"
      },
      "source": [
        "# 유니코드 파일을 아스키 코드 파일로 변환합니다.\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # 단어와 단어 뒤에 오는 구두점(.)사이에 공백을 생성합니다.\n",
        "  # 예시: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # 참고:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")을 제외한 모든 것을 공백으로 대체합니다.\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # 모델이 예측을 시작하거나 중단할 때를 알게 하기 위해서\n",
        "  # 문장에 start와 end 토큰을 추가합니다.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvfW9HTkENRY"
      },
      "source": [
        "# 유니코드 파일을 아스키 코드 파일로 변환합니다.\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # 단어와 단어 뒤에 오는 구두점(.)사이에 공백을 생성합니다.\n",
        "  # 예시: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # 참고:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")을 제외한 모든 것을 공백으로 대체합니다.\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # 모델이 예측을 시작하거나 중단할 때를 알게 하기 위해서\n",
        "  # 문장에 start와 end 토큰을 추가합니다.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-F4WMDUEQfz",
        "outputId": "3bc0598e-a149-41a4-d853-ffe63e36e686"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> may i borrow this book ? <end>\nb'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwfUamL2Mcpn"
      },
      "source": [
        "# [영어, 스페인어] 쌍 shuffle file 새로 저장\n",
        "# 모델 테스트 시 주석 꼭!\n",
        "# lines = io.open(path_to_file, encoding='UTF-8').read().strip().split('\\n')\n",
        "# random.shuffle(lines)\n",
        "# # 셔플된 리스트를 새로운 파일에 저장 , file name : shuffle_spa-eng.txt\n",
        "# f = open(path_to_shuffle_file3, 'w')\n",
        "# for i in lines:\n",
        "#     data = i + '\\n'\n",
        "#     f.write(data)\n",
        "# f.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VXgr4_2EUgt"
      },
      "source": [
        "# 1. 문장에 있는 억양을 제거합니다.\n",
        "# 2. 불필요한 문자를 제거하여 문장을 정리합니다.\n",
        "# 3. 다음과 같은 형식으로 문장의 쌍을 반환합니다: [영어, 스페인어]\n",
        "def create_dataset(path, num_examples):\n",
        "  # shuffle 된 데이터 파일에서 [영어, 스페인어] 쌍 생성\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  # 리스트에서 num_examples 까지 선택\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufBMIjKMEbQH",
        "outputId": "6e6f9b80-538a-4be8-ca61-1cf4970f88f3"
      },
      "source": [
        "en, sp = create_dataset(path_to_shuffle_file3, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])\n",
        "print(len(en), len(sp))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> i don t blame you for the accident . it wasn t your fault . <end>\n<start> no te culpo por el accidente . no fue culpa tuya . <end>\n118964 118964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9VUFvjLEdER"
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc4Rbx8JEjQZ"
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # 전처리된 타겟 문장과 입력 문장 쌍을 생성합니다.\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioibz-1bEkx-"
      },
      "source": [
        "# 언어 데이터셋을 아래의 크기로 제한하여 훈련과 검증을 수행합니다.\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_shuffle_file3, num_examples)\n",
        "\n",
        "# 타겟 텐서와 입력 텐서의 최대 길이를 계산합니다.\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAt188iPEpFc",
        "outputId": "1951927c-5697-4923-a77b-206e969541ef"
      },
      "source": [
        "# 훈련 집합과 검증 집합을 80대 20으로 분리합니다.\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# 훈련 집합과 검증 집합의 데이터 크기를 출력합니다.\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24000 24000 6000 6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwDUP11tErzK"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ6RIgYxEu7d",
        "outputId": "78cecde7-6b44-445a-e682-ab7466a3a730"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Language; index to word mapping\n1 ----> <start>\n102 ----> hoy\n9 ----> tom\n515 ----> llevo\n15 ----> un\n138 ----> nuevo\n821 ----> abrigo\n7 ----> a\n10 ----> la\n201 ----> escuela\n3 ----> .\n2 ----> <end>\n\nTarget Language; index to word mapping\n1 ----> <start>\n8 ----> tom\n1749 ----> wore\n9 ----> a\n126 ----> new\n794 ----> coat\n6 ----> to\n152 ----> school\n132 ----> today\n3 ----> .\n2 ----> <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU7tb2GYEvZX"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1777jlZSE5mz",
        "outputId": "1dc5bb93-3a7a-4e62-844c-dab2ea00e275"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 39]), TensorShape([64, 39]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvYcCHoFE7UY"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsoTBEKRFgkQ",
        "outputId": "57cdfa85-a321-46a2-e1a5-992ce64e0746"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# 샘플 입력\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 39, 1024)\nEncoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T7avh_BFVZN"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # 쿼리 은닉 상태(query hidden state)는 (batch_size, hidden size)쌍으로 이루어져 있습니다.\n",
        "    # query_with_time_axis은 (batch_size, 1, hidden size)쌍으로 이루어져 있습니다.\n",
        "    # values는 (batch_size, max_len, hidden size)쌍으로 이루어져 있습니다.\n",
        "    # 스코어(score)계산을 위해 덧셈을 수행하고자 시간 축을 확장하여 아래의 과정을 수행합니다.\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score는 (batch_size, max_length, 1)쌍으로 이루어져 있습니다.\n",
        "    # score를 self.V에 적용하기 때문에 마지막 축에 1을 얻습니다.\n",
        "    # self.V에 적용하기 전에 텐서는 (batch_size, max_length, units)쌍으로 이루어져 있습니다.\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights는 (batch_size, max_length, 1)쌍으로 이루어져 있습니다. \n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # 덧셈이후 컨텍스트 벡터(context_vector)는 (batch_size, hidden_size)쌍으로 이루어져 있습니다.\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTdKGGaWFXuF",
        "outputId": "4b75e238-8348-4966-c061-88a1d0db59cd"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\nAttention weights shape: (batch_size, sequence_length, 1) (64, 39, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weUzeqB1FaVk"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # 어텐션을 사용합니다.\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output는 (batch_size, max_length, hidden_size)쌍으로 이루어져 있습니다.\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # 임베딩층을 통과한 후 x는 (batch_size, 1, embedding_dim)쌍으로 이루어져 있습니다.\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # 컨텍스트 벡터와 임베딩 결과를 결합한 이후 x의 형태는 (batch_size, 1, embedding_dim + hidden_size)쌍으로 이루어져 있습니다.\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # 위에서 결합된 벡터를 GRU에 전달합니다.\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output은 (batch_size * 1, hidden_size)쌍으로 이루어져 있습니다.\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output은 (batch_size, vocab)쌍으로 이루어져 있습니다.\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoeGR2CsFk8E",
        "outputId": "50a7c8f9-0c22-44e2-d930-3c9fe75d5589"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 7786)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFs5xbUXFmPH"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7GWRTtRFoGz"
      },
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/Colab Notebooks/training_checkpoints_randomly data'\n",
        "checkpoint_dir2 = '/content/drive/MyDrive/Colab Notebooks/training_checkpoints_randomly data2'\n",
        "checkpoint_dir3 = '/content/drive/MyDrive/Colab Notebooks/training_checkpoints_randomly data3'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir3, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am5B-h1maP4_"
      },
      "source": [],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydveA1RlFp8u"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # 교사 강요(teacher forcing) - 다음 입력으로 타겟을 피딩(feeding)합니다.\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # enc_output를 디코더에 전달합니다.\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # 교사 강요(teacher forcing)를 사용합니다.\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KizVpKbFst7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7441f4b8-eed4-4e6b-cf09-a033b5a23c77"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    \n",
        "    total_loss += batch_loss\n",
        "    \n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # 에포크가 2번 실행될때마다 모델 저장 (체크포인트)\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for 바로 뒤\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "predictions\n",
            "batch_loss\n",
            "total_loss\n",
            "Epoch 1 Batch 0 Loss 2.0606\n",
            "for 바로 뒤\n",
            "batch_loss\n",
            "total_loss\n",
            "for 바로 뒤\n",
            "batch_loss\n",
            "total_loss\n",
            "for 바로 뒤\n",
            "batch_loss\n",
            "total_loss\n",
            "for 바로 뒤\n",
            "batch_loss\n",
            "total_loss\n",
            "for 바로 뒤\n",
            "batch_loss\n",
            "total_loss\n",
            "for 바로 뒤\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-29-a5c368686fa2>\", line 11, in <module>\n",
            "    batch_loss = train_step(inp, targ, enc_hidden)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 611, in _call\n",
            "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2420, in __call__\n",
            "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1665, in _filtered_call\n",
            "    self.captured_inputs)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1746, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 598, in call\n",
            "    ctx=ctx)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/posixpath.py\", line 416, in _joinrealpath\n",
            "    if not name or name == curdir:\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-29-a5c368686fa2>\", line 11, in <module>\n",
            "    batch_loss = train_step(inp, targ, enc_hidden)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 611, in _call\n",
            "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2420, in __call__\n",
            "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1665, in _filtered_call\n",
            "    self.captured_inputs)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1746, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 598, in call\n",
            "    ctx=ctx)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3360, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
            "    value, tb, tb_offset=tb_offset)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
            "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
            "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
            "    tb_offset)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
            "    if not islink(newpath):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/posixpath.py\", line 171, in islink\n",
            "    st = os.lstat(path)\n",
            "KeyboardInterrupt\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-29-a5c368686fa2>\", line 11, in <module>\n",
            "    batch_loss = train_step(inp, targ, enc_hidden)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 611, in _call\n",
            "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2420, in __call__\n",
            "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1665, in _filtered_call\n",
            "    self.captured_inputs)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1746, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 598, in call\n",
            "    ctx=ctx)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3360, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
            "    value, tb, tb_offset=tb_offset)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
            "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
            "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
            "    tb_offset)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3282, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
            "    value, tb, tb_offset=tb_offset)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
            "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
            "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1211, in structured_traceback\n",
            "    chained_exceptions_tb_offset)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/posixpath.py\", line 428, in _joinrealpath\n",
            "    newpath = join(path, name)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/posixpath.py\", line 81, in join\n",
            "    sep = _get_sep(a)\n",
            "  File \"/opt/anaconda3/envs/tensorflow/lib/python3.6/posixpath.py\", line 42, in _get_sep\n",
            "    if isinstance(path, bytes):\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-wAUSiGFujZ"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 문장, input 딕셔너리 출력 \n",
        "  # print ('sentence:', sentence)\n",
        "  # print ('inp_lang.word_index : ', inp_lang.word_index)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  # print('inputs: ', inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "\n",
        "  # Target 딕셔너리 출력\n",
        "  # print('targ_lang.word_index:', targ_lang.word_index)\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # 나중에 어텐션 가중치를 시각화하기 위해 어텐션 가중치를 저장합니다.\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    \n",
        "    # # argmax 되기 전 배열 값 알아보기\n",
        "    # print (\"dec_input : \", dec_input)\n",
        "    # print (\"predictions: \", predictions)\n",
        "    # print (\"predictions[0] : \", predictions[0])\n",
        "    # print (\"predicted_id : \", predicted_id)\n",
        "\n",
        "    # # argmax 전 단계 출력해보기\n",
        "    # print(\"predicted_id:\", predicted_id)\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # 예측된 ID를 모델에 다시 피드합니다.\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    # print(\"for 문 후 dec_input : \", dec_input)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4G4trudvJdR"
      },
      "source": [
        "# 어텐션 가중치를 그리기 위한 함수입니다.\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1uJo_rwvQxJ"
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  # attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  # plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypD8jH0QvV6-",
        "outputId": "f46b8305-4f52-4b09-8428-26be461f6070"
      },
      "source": [
        "# checkpoint_dir내에 있는 최근 체크포인트(checkpoint)를 복원합니다.\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir3))\n",
        "print(checkpoint_dir3)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/training_checkpoints_randomly data3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUDjZTCKvZA5",
        "outputId": "5117c6f4-c593-4533-9ee2-6186049655b0"
      },
      "source": [
        "translate(u'hace mucho frio aqui.') # it s very cold here"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s very cold here . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76Goju9Rvch8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f37075f4-77bc-479c-ce7f-7fe4a345fab9"
      },
      "source": [
        "translate(u'esta es mi vida.')  # this is my life"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM8hR2dtvfmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b981c09b-dc52-41f1-b340-013fb0354895"
      },
      "source": [
        "translate(u'¿todavia estan en casa?') # Are you still at home?"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> ¿ todavia estan en casa ? <end>\n",
            "Predicted translation: is still at home ? <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTXXZwkdvg_Y",
        "outputId": "346288b8-4a9f-4f24-cb8e-c816421b50dd"
      },
      "source": [
        "# 잘못된 번역\n",
        "translate(u'trata de averiguarlo.') # try to find out / try to figure out"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> trata de averiguarlo . <end>\n",
            "Predicted translation: keep on tom . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvrhSTomviTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f80f1a2-721b-4294-e193-257c2e738a94"
      },
      "source": [
        "translate(u'Te quiero.')   # I love you"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> te quiero . <end>\n",
            "Predicted translation: i love you . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycuk2NG8mogZ",
        "outputId": "0190bf46-73c5-49f4-fc17-8130986f18dc"
      },
      "source": [
        "translate(u'¿Que almorzaste hoy?')   # What did you have for lunch today?"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> ¿ que almorzaste hoy ? <end>\n",
            "Predicted translation: what did you have for lunch today ? <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lmK3xo0neZU",
        "outputId": "2aff0589-28d4-4caf-9be8-9fd9dafd1207"
      },
      "source": [
        "translate(u'El va a la escuela.')   # He is going to school."
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> el va a la escuela . <end>\n",
            "Predicted translation: he goes to school . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}